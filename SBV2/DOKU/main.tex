\documentclass[12pt,german]{article}
\usepackage{listings}
%\usepackage[utf8]{inputenc}
\usepackage{inputenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage{array}
\usepackage{pdfpages}

\lstset{
extendedchars=\true,
language=JAVA,
%inputencoding=utf8,
%basicstyle=\ttfamily,
%basicstyle=\ttfamily\fontsize{8}{8},
%commentstyle=\ttfamily\fontsize{8}{8},
basicstyle=\tiny;
columns=fullflexible,
%xleftmargin=5pt,
frame=single,
breaklines=true,
postbreak=\mbox{{$\hookrightarrow$}\space},
}
\renewcommand{\thesubsubsection}{\alph{subsubsection} )}
%\renewcommand{\thesubsubsection}{\thesubsection.\alph{subsubsection} )}

\begin{document}

\title{Übungsaufgaben II, SBV1 }
\author{Lisa Panholzer, Lukas Fiel}
\maketitle


\newpage
\section{Übungsaufgaben II}
\subsection{Resampling und Interpolation}
\subsubsection{Implementierung Resampling}

\subsubsection{Implementierung Bi-Lineare Interpolation}

\subsubsection{Implementierung Checker-Board}

\subsection{Klassifizierung mittels Kompression}
\subsubsection{Klassifizierung von Texten}

\textbf{Idee}

Aus Texten in 8 verschiedenen Sprachen soll mittels Kompression eine Klassifizierung stattfinden. Dazu wurden folgende Datensätze als \" *.txt \" Datein vorbereitet:

\begin{itemize}
	\item Abstract einer wissenschaftlichen Arbeit. Diese hatte den Vorteil dass es eine deutsche und englische Übersetzung gab. Alle weiteren Sprachen wurden aus der englischen Version mittels \textit{google translate} generiert.
	\item Wörterbuch mit 10000 deutschen Wörtern. Dieser Datensatz wurde mittels \textit{google translate} in alle anderen Sprachen übersetzt.
	\item Die erste Seite der Datenschutzrichtlinien von Facebook. Da die Datenschutzrichtlinien in sämtlichen Sprachen abrufbar sind, konnte für alle Sprachen ein passender Datensatz gefunden werden.
	\item Die erste Seite der Datenschutzrichtlinien von Google. Auch hier waren Daten in allen Sprachen verfügbar.
	\item Ein Witz der aus dem deutschen mittels \textit{google translate} in alle andern Sprachen übersetzt wurde.
\end{itemize}

Da nach einer Übersetzung die Texte in verschiedenen Sprachen ungleich viele Buchstaben beinhalten ist auch die Dateigröße unterschiedlich. Dies könnte eventuell rechnerisch berücksichtigt werden. Viel einfacher aber ist es, die letzten Buchstaben jedes langen Textes zu ignorieren und so eine einheitliche Länge des Textes zu gewährleisten. Dies wurde mittels eines shell-Skripts erreicht, welches nur die ersten $n$ Bytes eines Files speichert. So konnte für jeden Text eine Datei erzeugt werden die in allen Sprachen den selben Speicherbedarf hat. Der Verlust der letzten Byte ist bei einer Klassifizierung unwesentlich. 

\lstinputlisting[frame=single,language=MATLAB,breaklines=true]{../cutData.sh}

Nach einer solchen Normierung der Texte können diese miteinander verglichen werden. Dazu wurde ein Programm in \textit{Octave} geschrieben (siehe Listing \ref{fig: calculateMatrixOctaveCode}  , welches die Texte der einzelnen Datensätze miteinander vergleicht und in einer Matrix darstellt. Eine qualitativ hochwertige Aussage ob die Ergebisse statistische Aussagekraft haben, kann mit $5$ Datensätzen nicht getroffen werden. Es ist aber sicherlich ein Trend erkennbar.


\begin{figure}[H]
	\centering
	\includegraphics[width=12cm]{images/resultZipData.jpg}
	\caption{zipDataMatrix}
	\label{fig: zipDataMatrix}
\end{figure}

\newpage
\lstinputlisting[frame=single,language=MATLAB,breaklines=true,caption = Octave Script zur Darstellung der einzelnen Kompressionsraten.]{../calculateZipMatrix.m}
\label{fig: calculateMatrixOctaveCode}


\subsubsection{OPTIONAL – nur für Interessierte/Experten}


\subsection{Kompression und Code-Transformation}
\subsubsection{Lempel-Ziv Kompression einer Sequenz}
Figure \ref{fig: manualLemperZivPdf} zeigt die händische Berechnung der Lemper Ziv Kompression. Beim Übertragen ins Protokoll wurde allerdings ein Fehler entdeckt, der in Tabelle \ref{tab:Level Ziv Kompression} korrigiert wurde.



\includepdf[scale=0.4]{images/lemperZiv.pdf}
\label{fig: manualLemperZivPdf}


\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c | c | c |}
    \hline
   	aktuelles  & nächstes  & Ausgabe  & ins & Speicher \\
   	 Zeichen &  Zeichen &  (im Wörterbuch?) & Wörterbuch! &  \\
	a & b & N $ \rightarrow $ a & ab & 256 \\
	b & a & N $ \rightarrow $ b & ba & 257 \\
	a & b & Y $ \rightarrow $ 256 & aba & 258 \\
	a & b & Y $ \rightarrow $ 256 & abb & 259 \\
	b & b & N $ \rightarrow $ b & bb & 260 \\
	b & a & Y $ \rightarrow $ 257 & baa & 261 \\
	a & a & N $ \rightarrow $ a & aa & 262 \\
	a & a & Y $ \rightarrow $ 256 & aab & 263 \\
	b & a & Y $ \rightarrow $ 257 & bab & 264 \\
	b & a & Y (257), Y $ \rightarrow $ 264 & babc & 265 \\
	c & c & N $ \rightarrow $ c & cc & 266 \\
	c & d & N $ \rightarrow $ c & cd & 267 \\
	d & d & N $ \rightarrow $ d & dd & 268 \\
	d & d & Y $ \rightarrow $ 268 & dda & 269 \\
	a &   & N $ \rightarrow $ a &     &   \\ 
   	
  \end{tabular}
  \caption{Level Ziv Kompression}
  \label{tab:Level Ziv Kompression}
\end{table}

In der korrigierten Version ergibt die resultierende Zeichenkette: 

\begin{table}[H]
  \centering
  \begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c | c | c | c | c |}
    \hline
    97 & 98& 256 & 256 & 98 & 257 & 97 & 262 & 257 & 264 & 99 & 99 & 100 & 268 & 269 \\
    \hline
  \end{tabular}
\end{table}


\begin{equation}[H]
 Kompressionsrate C = \frac{23}{15} = 1.5334	
\end{equation}


\subsubsection{Huffmann Coding}

Die nächste Seite zeigt die händische Berechnung des Huffmann Baums zum gegebenen Beispiel. Die mittlere Codewortlänge lieght dabei bei $1.869 bit $. \\

Weiters kann man auf der darauffolgenden Seite die manuelle Berechnung von 6 Testfällen finden. Es kann gesagt werden, dass die Huffmann Kompression sehr gut geeignet wäre um Daten zu komprimieren, die sehr oft gleich sind. Dabei spielt homogenität keine Rolle, sondern rein die Häufigkeit des Auftretens der Sonderfälle. An diser Stelle sei erwähbt, dass die Information über solche Sonderfälle nicht verlohren geht, sondern einfach mehr Speicher benötigt (verlusstfreies Komprimieren)

\includepdf{images/huffmannBerechnung.pdf}
\label{fig:huffmannCalculation}

\includepdf{images/huffmannTestfaelle.pdf}
\label{fig:huffmannCalculation}


\subsubsection{Kompression einer Sequenz}

\subsubsection{Entropieberechnung}
\end{document}
